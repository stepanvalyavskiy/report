\documentclass[acmlarge, screen, nonacm]{acmart}
\usepackage[utf8]{inputenc}
\usepackage{float}
\usepackage{setspace}
\usepackage{pgfplots}
\usepackage{graphicx}
\usepackage{fancyvrb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
  \hypersetup{colorlinks=true,allcolors=blue!40!black}
\setlength{\topskip}{6pt}
\setlength{\parindent}{0pt} % indent first line
\setlength{\parskip}{6pt} % before par

\title{Implementation of consensus algorithms on git side}

\author{Stepan Valiavskii}
\email{stepan.valiavskii@huawei.com}

\begin{document}

\begin{abstract}
To achieve strong consistency in DeGitX we need to solve a problem of atomic commit over N git servers.
It isn't always possible to undo changes in git, so we need to manage git transactions and provide abortion mechanism as well.
Fortunately, we aren't the first who met the problem of atomic commit.
There are several well known algorithms as: 2PC, 3PC and Paxos-Commit.
Theoretically, each of them could solve our problem.
We have investigated how they could be implemented with git.
We stay on 2PC integrated in git reference transaction hook.
The problem is particularly solved.
Now we need to implement it and do benchmarking.
\end{abstract}

\maketitle

\section{Problem}

DeGitX keep three copies of every repository on three different servers.
We need to keep repositories fully
available without interruption even if one of those servers goes down.
Even in the extreme case that two copies of a repository become unavailable at
the same time, the repository should remains readable, i.e., fetches, clones, and
most of the web UI continue to work.
We need to implement replication at the application layer, rather than at the disk layer.
When the replicas are three loosely-coupled Git repositories kept
in sync via Git protocols, rather than identical disk images full of repositories,
it gives us great flexibility to decide where to
store the replicas of a repository and which replica to use for read operations.

To split read traffic over replicas and to remain repository readable even if two copies become unavailable,
we need to ensure that every Git update is safely replicated to all of the replicas in most cases
and to at least a quorum of replicas in every case.

So what should be done to do an atomic commit in 3 git replicas:
\begin{enumerate}
  \item on each node: lock all data that going to be changed (this sync section should be extremely small).
  \item on each node: verify if commit could be accepted.
  \item do voting and notify all nodes about decision: accept or discard.
  \item accept/discard changes on all nodes or at least on quorum.
  \item release locks.
  \item schedule replication for outdated node, if changes were accepted by quorum (2/3 nodes) and mark node as outdated (Such node stops accepts read requests till restoring).
  \item replicate outdated node.
\end{enumerate}

\section{Related works}

GitHub Spokes - not open sourced.

Spokes uses the three-phase commit protocol to update the replicas and additionally use the replicas as a distributed lock
to ensure that the database is updated in the correct order.
All in all, this costs four round-trips to the distant replicas;
expensive, but not prohibitive.
(Spokes has plans to reduce the number of round trips through the use of a more advanced consensus algorithm.)

As much as possible, Spokes also makes use of the time spent waiting on the network to get other work done.
For example, while one replica is acquiring its lock,
another replica might be computing a checksum and the coordinator might be reading from the database.

\emph{\href{https://gitlab.com/groups/gitlab-org/-/epics/1189}{Gitaly HA}} - not yet ready.

Gitaly Cluster allows Git repositories to be replicated on multiple warm Gitaly nodes.
This improves fault tolerance by removing single points of failure.
Reference transactions, introduced in GitLab 13.3,
causes changes to be broadcast to all the Gitaly nodes in the cluster,
but only the Gitaly nodes that vote in agreement with the primary node persist the changes to disk.
If all the replica nodes dissented, only one copy of the change would be persisted to disk,
creating a single point of failure until asynchronous replication completed.

Quorum-based voting improves fault tolerance by requiring a majority of nodes to agree before persisting changes to disk.
When the feature flag is enabled, writes must succeed on multiple nodes.
Dissenting nodes are automatically brought in sync by asynchronous replication from the nodes that formed the quorum.

It's currently in alpha and not enabled by default.
If enabled, transactions are only available for a subset of Gitaly RPCs.

\section{Solution}

How to Lock:

We don't want to block all writes while someone is pushing a payload,
but we want to start the transaction right before a user attempts to write new refs.
With this approach only reference update will be synchronised and objects are uploaded asynchronously.

So we need to lock on all git reference update operations.
Git \emph{\href{https://git-scm.com/docs/githooks.html\#_reference_transaction}{reference-transaction hook}}
handles all reference update operations and queues reference updates to the transaction and locks reference updates on disk.
In the ``prepared" state, a non-zero exit status will cause the transaction to be aborted.
And zero status - to be committed.
After that lock will be released.

So everything seems to be ready from the box.
We need only implement voting here and return zero status if all replicas/quorum have been agreed, and non-zero if quorum isn't reached.
As soon as it gets called, it will take all
of stdin and use it to cast a vote to a central service.
The most important upside is that this will catch all commands writing
references at once, allowing to implement strong consistency for
reference updates via a single mechanism.
Each of the hooks will block until it receives a message from coordinator telling to to either go on with the update or to abort.

So the solution is: implement atomic commit protocol in git reference transaction hook.

The question is only which one to implement?

The most common atomic commit protocol is
\emph{\href{https://en.wikipedia.org/wiki/Two-phase_commit_protocol}{2PC}}.
It is the most optimised protocol in fault-free case.
2PC has a coordinator that decides whether to commit (only if all have voted "Yes") or abort the transaction (otherwise),
and notifies the result to all the participants.
The greatest disadvantage of the two-phase commit protocol is that it is a blocking protocol.
If the coordinator fails permanently, some participants will never resolve their transactions:
After a participant has sent an agreement message to the coordinator, it will block until a commit or rollback is received.

There are 2 protocols that make an atomic commit fault-tolerant:
\emph{\href{https://dsf.berkeley.edu/cs286/papers/paxoscommit-tods2006.pdf}{Paxos-Commit}}
and
\emph{\href{https://en.wikipedia.org/wiki/Three-phase_commit_protocol}{3PC}}.
But they solve it in completely different ways:

Paxos-Commit makes it fault-tolerant by simply using a consensus
algorithm to choose the committed/aborted decision.
Paxos-Commit uses
\emph{\href{https://en.wikipedia.org/wiki/Atomic_broadcast}{Total Order Broadcast}}
to notify each participants about it's decision directly.
So each node can decide weather commit or abort without any coordinator.
It's required a leader and leader election phase.

3PC still uses coordinator to make any decision but it provides additional phase that makes coordinator stateless and replaceable.

A two-phase commit protocol cannot dependably recover
from a failure of both the coordinator and a cohort member during the Commit phase.
If only the coordinator had failed, and no cohort members had received a commit message,
it could safely be inferred that no commit had happened.
If, however, both the coordinator and a cohort member failed,
it is possible that the failed cohort member was the first to be notified,
and had actually done the commit.
Even if a new coordinator is selected,
it cannot confidently proceed with the operation until it has received an agreement from all cohort members,
and hence must block until all cohort members respond.

The three-phase commit protocol eliminates this problem by introducing the Prepared to commit state.
If the coordinator fails before sending preCommit messages,
the cohort will unanimously agree that the operation was aborted.
The coordinator will not send out a doCommit message until all cohort members have ACKed that they are Prepared to commit.
This eliminates the possibility that any cohort member actually completed the transaction
before all cohort members were aware of the decision to do so (an ambiguity that necessitated indefinite blocking in the two-phase commit protocol).

So there are 2 approaches:
\begin{enumerate}
  \item Node Orchestrated: Node orchestrating puts the intelligence of replication into one of the nodes being modified.
Orchestration requires designating a leader node for the transaction.
This leader node becomes a critical path for all nodes involved.
  \item Coordinator Orchestrated: Coordinator orchestrating isolates the critical path to a stateless coordinator.
\end{enumerate}

Both GitHub Spokes and Gitaly HA have chosen 3PC. And that's why:

If we have operations that can succeed/fail independently of each other, then failure and recovery can be handled externally of the nodes.
Stateless coordinators are preferred for the critical path since another one can pick up the task after failure.

The question is answered: 3PC fits best to achieve strong consistency.

\section{Future work}

\begin{enumerate}
  \item compare atomic commit protocols: 2PC, 3PC, Paxos-commit
  \item implement and do benchmarking
  \item investigate self-healing mechanism
\end{enumerate}

\section{Conclusion}

Now DeGitX team has vision how to achieve strong consistency.

To simplify we decided to use two-phase commit protocol at first and finally migrate to the three-phase commit protocol.
Voting Strategies: at first the strongest voting strategy is chosen:
all nodes have to agree before committing anything.
Further it could be allowed to commit if quorum is reached.

pros:
\begin{itemize}
  \item simple
  \item strong consistent
\end{itemize}

cons:
\begin{itemize}
  \item if a single replica fails, repository becomes read-only
\end{itemize}

\end{document}
